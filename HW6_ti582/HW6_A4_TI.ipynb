{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# By: Thomas Isola\n",
    "## Class: PUI 2018\n",
    "## HW #6 Assignment 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Assignment 4 Goal**:  \n",
    "- Test if the distribution of: trip duration of bikers that ride during the day vs night are different.  \n",
    "- Use 3 tests: KS, Pearson's, Spearman's.  \n",
    "- Use the scipy.stats functions scipy.stats.ks_2samp, scipy.stats.pearsonr, scipy.stats.spearmanr.  \n",
    "- For the KS do the test with the entire dataset and with a subset 200 times smaller.  \n",
    "- Choose a single significant threshold for the whole exercise.  \n",
    "- For each test, phrase the Null Hypothesis in words. Describe the return of the scipy function you use in each case. State the result in terms of rejection of the Null."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "# Import packages\n",
    "import pylab as pl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import scipy.stats\n",
    "#imports downloader\n",
    "from getCitiBikeCSV import getCitiBikeCSV\n",
    "\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Test Null Hypotheses\n",
    "For all tests, I will use $\\alpha = 0.05$\n",
    "### 2 sample K-S Test\n",
    "**H0**: The two samples (daytime trip duration and nighttime trip duration) come from the same continuous distribution.\n",
    "### Pearson's test for correlation\n",
    "**H0**: The two samples (daytime trip duration and nighttime trip duration) are not correlated.\n",
    "### Spearman's test for correlation\n",
    "**H0**: The two samples (daytime trip duration and nighttime trip duration) are not correlated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 201602\n",
      "file in place, you can continue\n"
     ]
    }
   ],
   "source": [
    "# Download desired months of Citibike data\n",
    "\n",
    "# First month (warmer month)\n",
    "datestring1 = '201602'\n",
    "getCitiBikeCSV(datestring1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 201608\n",
      "file in place, you can continue\n"
     ]
    }
   ],
   "source": [
    "# Second month (colder month)\n",
    "datestring2 = '201608'\n",
    "getCitiBikeCSV(datestring2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the data to pandas dataframes\n",
    "df1 = pd.read_csv(os.getenv(\"PUIDATA\") + \"/\" + datestring1 + '-citibike-tripdata.csv')\n",
    "df2 = pd.read_csv(os.getenv(\"PUIDATA\") + \"/\" + datestring2 + '-citibike-tripdata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the dataframes\n",
    "df3 = pd.concat([df1, df2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['tripduration', 'starttime', 'stoptime', 'start station id',\n",
       "       'start station name', 'start station latitude',\n",
       "       'start station longitude', 'end station id', 'end station name',\n",
       "       'end station latitude', 'end station longitude', 'bikeid', 'usertype',\n",
       "       'birth year', 'gender'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the columns\n",
    "df3.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tripduration</th>\n",
       "      <th>starttime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>461</td>\n",
       "      <td>2/1/2016 00:00:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>297</td>\n",
       "      <td>2/1/2016 00:00:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>280</td>\n",
       "      <td>2/1/2016 00:01:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>662</td>\n",
       "      <td>2/1/2016 00:01:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>355</td>\n",
       "      <td>2/1/2016 00:01:41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tripduration          starttime\n",
       "0           461  2/1/2016 00:00:08\n",
       "1           297  2/1/2016 00:00:56\n",
       "2           280  2/1/2016 00:01:00\n",
       "3           662  2/1/2016 00:01:00\n",
       "4           355  2/1/2016 00:01:41"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the unnecessary columns\n",
    "df3.drop(['stoptime','start station id','start station name','start station latitude',\n",
    "         'start station longitude','end station id','end station name','end station latitude',\n",
    "          'end station longitude','bikeid','usertype','birth year','gender'], axis=1, inplace=True)\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tripduration</th>\n",
       "      <th>starttime</th>\n",
       "      <th>Day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>461</td>\n",
       "      <td>2/1/2016 00:00:08</td>\n",
       "      <td>Night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>297</td>\n",
       "      <td>2/1/2016 00:00:56</td>\n",
       "      <td>Night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>280</td>\n",
       "      <td>2/1/2016 00:01:00</td>\n",
       "      <td>Night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>662</td>\n",
       "      <td>2/1/2016 00:01:00</td>\n",
       "      <td>Night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>355</td>\n",
       "      <td>2/1/2016 00:01:41</td>\n",
       "      <td>Night</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tripduration          starttime    Day\n",
       "0           461  2/1/2016 00:00:08  Night\n",
       "1           297  2/1/2016 00:00:56  Night\n",
       "2           280  2/1/2016 00:01:00  Night\n",
       "3           662  2/1/2016 00:01:00  Night\n",
       "4           355  2/1/2016 00:01:41  Night"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter the data by day and night\n",
    "# For this assignment, I am using 6AM - 6PM as day and otherwise it is night\n",
    "df3['Day'] = np.where(((df3.starttime > '2/1/2016 06:00:00') & (df3.starttime < '2/1/2016 18:00:00')) \n",
    "                      | ((df3.starttime > '2/2/2016 06:00:00') & (df3.starttime < '2/2/2016 18:00:00'))\n",
    "                      | ((df3.starttime > '2/3/2016 06:00:00') & (df3.starttime < '2/3/2016 18:00:00'))\n",
    "                      | ((df3.starttime > '2/4/2016 06:00:00') & (df3.starttime < '2/4/2016 18:00:00'))\n",
    "                      | ((df3.starttime > '2/5/2016 06:00:00') & (df3.starttime < '2/5/2016 18:00:00'))\n",
    "                      | ((df3.starttime > '2/6/2016 06:00:00') & (df3.starttime < '2/6/2016 18:00:00'))\n",
    "                      | ((df3.starttime > '2/7/2016 06:00:00') & (df3.starttime < '2/7/2016 18:00:00'))\n",
    "                      | ((df3.starttime > '2/8/2016 06:00:00') & (df3.starttime < '2/8/2016 18:00:00'))\n",
    "                      | ((df3.starttime > '2/9/2016 06:00:00') & (df3.starttime < '2/9/2016 18:00:00'))\n",
    "                      | ((df3.starttime > '2/10/2016 06:00:00') & (df3.starttime < '2/10/2016 18:00:00'))\n",
    "                      | ((df3.starttime > '2/11/2016 06:00:00') & (df3.starttime < '2/11/2016 18:00:00'))\n",
    "                      | ((df3.starttime > '2/12/2016 06:00:00') & (df3.starttime < '2/12/2016 18:00:00'))\n",
    "                      | ((df3.starttime > '2/13/2016 06:00:00') & (df3.starttime < '2/13/2016 18:00:00'))\n",
    "                      | ((df3.starttime > '2/14/2016 06:00:00') & (df3.starttime < '2/14/2016 18:00:00'))\n",
    "                      | ((df3.starttime > '2/15/2016 06:00:00') & (df3.starttime < '2/15/2016 18:00:00'))\n",
    "                      | ((df3.starttime > '2/16/2016 06:00:00') & (df3.starttime < '2/16/2016 18:00:00'))\n",
    "                      | ((df3.starttime > '2/17/2016 06:00:00') & (df3.starttime < '2/17/2016 18:00:00'))\n",
    "                      | ((df3.starttime > '2/18/2016 06:00:00') & (df3.starttime < '2/18/2016 18:00:00'))\n",
    "                      | ((df3.starttime > '2/19/2016 06:00:00') & (df3.starttime < '2/19/2016 18:00:00'))\n",
    "                      | ((df3.starttime > '2/20/2016 06:00:00') & (df3.starttime < '2/20/2016 18:00:00'))\n",
    "                      | ((df3.starttime > '2/21/2016 06:00:00') & (df3.starttime < '2/21/2016 18:00:00'))\n",
    "                      | ((df3.starttime > '2/22/2016 06:00:00') & (df3.starttime < '2/22/2016 18:00:00'))\n",
    "                      | ((df3.starttime > '2/23/2016 06:00:00') & (df3.starttime < '2/23/2016 18:00:00'))\n",
    "                      | ((df3.starttime > '2/24/2016 06:00:00') & (df3.starttime < '2/24/2016 18:00:00'))\n",
    "                      | ((df3.starttime > '2/25/2016 06:00:00') & (df3.starttime < '2/25/2016 18:00:00'))\n",
    "                      | ((df3.starttime > '2/26/2016 06:00:00') & (df3.starttime < '2/26/2016 18:00:00'))\n",
    "                      | ((df3.starttime > '2/27/2016 06:00:00') & (df3.starttime < '2/27/2016 18:00:00'))\n",
    "                      | ((df3.starttime > '2/28/2016 06:00:00') & (df3.starttime < '2/28/2016 18:00:00'))\n",
    "                      | ((df3.starttime > '2/29/2016 06:00:00') & (df3.starttime < '2/29/2016 18:00:00'))\n",
    "                      | ((df3.starttime > '8/1/2016 06:00:00') & (df3.starttime < '8/1/2016 18:00:00'))\n",
    "                      | ((df3.starttime > '8/2/2016 06:00:00') & (df3.starttime < '8/2/2016 18:00:00'))\n",
    "                      | ((df3.starttime > '8/3/2016 06:00:00') & (df3.starttime < '8/3/2016 18:00:00'))\n",
    "                      | ((df3.starttime > '8/4/2016 06:00:00') & (df3.starttime < '8/4/2016 18:00:00'))\n",
    "                      | ((df3.starttime > '8/5/2016 06:00:00') & (df3.starttime < '8/5/2016 18:00:00'))\n",
    "                      | ((df3.starttime > '8/6/2016 06:00:00') & (df3.starttime < '8/6/2016 18:00:00'))\n",
    "                      | ((df3.starttime > '8/7/2016 06:00:00') & (df3.starttime < '8/7/2016 18:00:00'))\n",
    "                      | ((df3.starttime > '8/8/2016 06:00:00') & (df3.starttime < '8/8/2016 18:00:00'))\n",
    "                      | ((df3.starttime > '8/9/2016 06:00:00') & (df3.starttime < '8/9/2016 18:00:00'))\n",
    "                      | ((df3.starttime > '8/10/2016 06:00:00') & (df3.starttime < '8/10/2016 18:00:00'))\n",
    "                      | ((df3.starttime > '8/11/2016 06:00:00') & (df3.starttime < '8/11/2016 18:00:00'))\n",
    "                      | ((df3.starttime > '8/12/2016 06:00:00') & (df3.starttime < '8/12/2016 18:00:00'))\n",
    "                      | ((df3.starttime > '8/13/2016 06:00:00') & (df3.starttime < '8/13/2016 18:00:00'))\n",
    "                      | ((df3.starttime > '8/14/2016 06:00:00') & (df3.starttime < '8/14/2016 18:00:00'))\n",
    "                      | ((df3.starttime > '8/15/2016 06:00:00') & (df3.starttime < '8/15/2016 18:00:00'))\n",
    "                      | ((df3.starttime > '8/16/2016 06:00:00') & (df3.starttime < '8/16/2016 18:00:00'))\n",
    "                      | ((df3.starttime > '8/17/2016 06:00:00') & (df3.starttime < '8/17/2016 18:00:00'))\n",
    "                      | ((df3.starttime > '8/18/2016 06:00:00') & (df3.starttime < '8/18/2016 18:00:00'))\n",
    "                      | ((df3.starttime > '8/19/2016 06:00:00') & (df3.starttime < '8/19/2016 18:00:00'))\n",
    "                      | ((df3.starttime > '8/20/2016 06:00:00') & (df3.starttime < '8/20/2016 18:00:00'))\n",
    "                      | ((df3.starttime > '8/21/2016 06:00:00') & (df3.starttime < '8/21/2016 18:00:00'))\n",
    "                      | ((df3.starttime > '8/22/2016 06:00:00') & (df3.starttime < '8/22/2016 18:00:00'))\n",
    "                      | ((df3.starttime > '8/23/2016 06:00:00') & (df3.starttime < '8/23/2016 18:00:00'))\n",
    "                      | ((df3.starttime > '8/24/2016 06:00:00') & (df3.starttime < '8/24/2016 18:00:00'))\n",
    "                      | ((df3.starttime > '8/25/2016 06:00:00') & (df3.starttime < '8/25/2016 18:00:00'))\n",
    "                      | ((df3.starttime > '8/26/2016 06:00:00') & (df3.starttime < '8/26/2016 18:00:00'))\n",
    "                      | ((df3.starttime > '8/27/2016 06:00:00') & (df3.starttime < '8/27/2016 18:00:00'))\n",
    "                      | ((df3.starttime > '8/28/2016 06:00:00') & (df3.starttime < '8/28/2016 18:00:00'))\n",
    "                      | ((df3.starttime > '8/29/2016 06:00:00') & (df3.starttime < '8/29/2016 18:00:00'))\n",
    "                      ,\"Day\",\"Night\")\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the day and night data\n",
    "dfNight = df3[df3.Day == \"Night\"]\n",
    "dfDay = df3[df3.Day == \"Day\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ks_2sampResult(statistic=0.0084213674921139736, pvalue=6.5945558267841418e-30)\n"
     ]
    }
   ],
   "source": [
    "# Perform the 2 sample K-S test\n",
    "ks = scipy.stats.ks_2samp(dfNight.tripduration,dfDay.tripduration)\n",
    "print(ks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The value of the K-S statistic is low and the pvalue is smaller than our chosen significance level of 0.05, therefore, the null hypothesis is rejected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select random slices of the day and night data of equal size  \n",
    "numpy.random.seed(100)\n",
    "dfNight_reduced = numpy.random.choice(dfNight.tripduration, size=200, replace=False)\n",
    "dfDay_reduced = numpy.random.choice(dfDay.tripduration, size=200, replace=False)\n",
    "dfNight_reduced.sort()\n",
    "dfDay_reduced.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.99901744324249409, 5.9941913280920799e-270)\n"
     ]
    }
   ],
   "source": [
    "# Perform Pearson's test for correlation\n",
    "pear = scipy.stats.pearsonr(dfNight_reduced, dfDay_reduced)\n",
    "print(pear)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The value of the correlation coefficient is high and the p-value is smaller than our chosen significance level of 0.05, therefore, the null hypothesis is rejected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpearmanrResult(correlation=0.99998799957201612, pvalue=0.0)\n"
     ]
    }
   ],
   "source": [
    "spear = scipy.stats.spearmanr(dfNight_reduced, dfDay_reduced)\n",
    "print(spear)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The value of the correlation coefficient is high and the p-value is smaller than our chosen significance level of 0.05, therefore, the null hypothesis is rejected."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PUI2016_Python3",
   "language": "python",
   "name": "pui2016_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
